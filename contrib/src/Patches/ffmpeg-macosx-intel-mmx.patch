Index: libavcodec/i386/motion_est_mmx.c
===================================================================
--- libavcodec/i386/motion_est_mmx.c	(revision 11270)
+++ libavcodec/i386/motion_est_mmx.c	(working copy)
@@ -167,7 +167,7 @@
 static inline void sad8_4_mmx2(uint8_t *blk1, uint8_t *blk2, int stride, int h)
 {
     asm volatile(
-        "movq "MANGLE(bone)", %%mm5     \n\t"
+        "movq %4, %%mm5     \n\t"
         "movq (%1), %%mm0               \n\t"
         "pavgb 1(%1), %%mm0             \n\t"
         "add %3, %1                     \n\t"
@@ -190,7 +190,7 @@
         "sub $2, %0                     \n\t"
         " jg 1b                         \n\t"
         : "+r" (h), "+r" (blk1), "+r" (blk2)
-        : "r" ((long)stride)
+        : "r" ((long)stride), "m" (bone)
     );
 }
 
@@ -258,7 +258,7 @@
         "punpckhbw %%mm7, %%mm5         \n\t"
         "paddw %%mm4, %%mm2             \n\t"
         "paddw %%mm5, %%mm3             \n\t"
-        "movq 16+"MANGLE(round_tab)", %%mm5 \n\t"
+        "movq 16+%5, %%mm5 \n\t"
         "paddw %%mm2, %%mm0             \n\t"
         "paddw %%mm3, %%mm1             \n\t"
         "paddw %%mm5, %%mm0             \n\t"
@@ -281,7 +281,7 @@
         "add %4, %%"REG_a"              \n\t"
         " js 1b                         \n\t"
         : "+a" (len)
-        : "r" (blk1 - len), "r" (blk1 -len + stride), "r" (blk2 - len), "r" ((long)stride)
+        : "r" (blk1 - len), "r" (blk1 -len + stride), "r" (blk2 - len), "r" ((long)stride), "m" (round_tab[0])
     );
 }
  
Index: libavcodec/i386/dsputil_mmx.c
===================================================================
--- libavcodec/i386/dsputil_mmx.c	(revision 11879)
+++ libavcodec/i386/dsputil_mmx.c	(working copy)
@@ -1927,7 +1927,7 @@
 
 #define QPEL_V_LOW(m3,m4,m5,m6, pw_20, pw_3, rnd, in0, in1, in2, in7, out, OP)\
         "paddw " #m4 ", " #m3 "           \n\t" /* x1 */\
-        "movq "MANGLE(ff_pw_20)", %%mm4   \n\t" /* 20 */\
+        "movq "#pw_20", %%mm4   \n\t" /* 20 */\
         "pmullw " #m3 ", %%mm4            \n\t" /* 20x1 */\
         "movq "#in7", " #m3 "             \n\t" /* d */\
         "movq "#in0", %%mm5               \n\t" /* D */\
@@ -1939,7 +1939,7 @@
         "paddw " #m5 ", %%mm6             \n\t" /* x2 */\
         "paddw %%mm6, %%mm6               \n\t" /* 2x2 */\
         "psubw %%mm6, %%mm5               \n\t" /* -2x2 + x3 */\
-        "pmullw "MANGLE(ff_pw_3)", %%mm5  \n\t" /* -6x2 + 3x3 */\
+        "pmullw "#pw_3", %%mm5  \n\t" /* -6x2 + 3x3 */\
         "paddw " #rnd ", %%mm4            \n\t" /* x2 */\
         "paddw %%mm4, %%mm5               \n\t" /* 20x1 - 6x2 + 3x3 - x4 */\
         "psraw $5, %%mm5                  \n\t"\
@@ -1973,10 +1973,10 @@
         "paddw %%mm5, %%mm5               \n\t" /* 2b */\
         "psubw %%mm5, %%mm6               \n\t" /* c - 2b */\
         "pshufw $0x06, %%mm0, %%mm5       \n\t" /* 0C0B0A0A */\
-        "pmullw "MANGLE(ff_pw_3)", %%mm6  \n\t" /* 3c - 6b */\
+        "pmullw %8, %%mm6  \n\t" /* 3c - 6b */\
         "paddw %%mm4, %%mm0               \n\t" /* a */\
         "paddw %%mm1, %%mm5               \n\t" /* d */\
-        "pmullw "MANGLE(ff_pw_20)", %%mm0 \n\t" /* 20a */\
+        "pmullw %7, %%mm0 \n\t" /* 20a */\
         "psubw %%mm5, %%mm0               \n\t" /* 20a - d */\
         "paddw %6, %%mm6                  \n\t"\
         "paddw %%mm6, %%mm0               \n\t" /* 20a - 6b + 3c - d */\
@@ -1999,10 +1999,10 @@
         "psrlq $24, %%mm6                 \n\t" /* IJKLM000 */\
         "punpcklbw %%mm7, %%mm2           \n\t" /* 0F0G0H0I */\
         "punpcklbw %%mm7, %%mm6           \n\t" /* 0I0J0K0L */\
-        "pmullw "MANGLE(ff_pw_3)", %%mm3  \n\t" /* 3c - 6b */\
+        "pmullw %8, %%mm3  \n\t" /* 3c - 6b */\
         "paddw %%mm2, %%mm1               \n\t" /* a */\
         "paddw %%mm6, %%mm4               \n\t" /* d */\
-        "pmullw "MANGLE(ff_pw_20)", %%mm1 \n\t" /* 20a */\
+        "pmullw %7, %%mm1 \n\t" /* 20a */\
         "psubw %%mm4, %%mm3               \n\t" /* - 6b +3c - d */\
         "paddw %6, %%mm1                  \n\t"\
         "paddw %%mm1, %%mm3               \n\t" /* 20a - 6b +3c - d */\
@@ -2025,7 +2025,7 @@
         "psubw %%mm5, %%mm0               \n\t" /* c - 2b */\
         "movq %%mm3, %%mm5                \n\t" /* JKLMNOPQ */\
         "psrlq $24, %%mm3                 \n\t" /* MNOPQ000 */\
-        "pmullw "MANGLE(ff_pw_3)", %%mm0  \n\t" /* 3c - 6b */\
+        "pmullw %8, %%mm0  \n\t" /* 3c - 6b */\
         "punpcklbw %%mm7, %%mm3           \n\t" /* 0M0N0O0P */\
         "paddw %%mm3, %%mm2               \n\t" /* d */\
         "psubw %%mm2, %%mm0               \n\t" /* -6b + 3c - d */\
@@ -2033,7 +2033,7 @@
         "punpcklbw %%mm7, %%mm2           \n\t" /* 0J0K0L0M */\
         "punpckhbw %%mm7, %%mm5           \n\t" /* 0N0O0P0Q */\
         "paddw %%mm2, %%mm6               \n\t" /* a */\
-        "pmullw "MANGLE(ff_pw_20)", %%mm6 \n\t" /* 20a */\
+        "pmullw %7, %%mm6 \n\t" /* 20a */\
         "paddw %6, %%mm0                  \n\t"\
         "paddw %%mm6, %%mm0               \n\t" /* 20a - 6b + 3c - d */\
         "psraw $5, %%mm0                  \n\t"\
@@ -2048,8 +2048,8 @@
         "paddw %%mm2, %%mm5               \n\t" /* d */\
         "paddw %%mm6, %%mm6               \n\t" /* 2b */\
         "psubw %%mm6, %%mm4               \n\t" /* c - 2b */\
-        "pmullw "MANGLE(ff_pw_20)", %%mm3 \n\t" /* 20a */\
-        "pmullw "MANGLE(ff_pw_3)", %%mm4  \n\t" /* 3c - 6b */\
+        "pmullw %7, %%mm3 \n\t" /* 20a */\
+        "pmullw %8, %%mm4  \n\t" /* 3c - 6b */\
         "psubw %%mm5, %%mm3               \n\t" /* -6b + 3c - d */\
         "paddw %6, %%mm4                  \n\t"\
         "paddw %%mm3, %%mm4               \n\t" /* 20a - 6b + 3c - d */\
@@ -2062,7 +2062,9 @@
         "decl %2                          \n\t"\
         " jnz 1b                          \n\t"\
         : "+a"(src), "+c"(dst), "+g"(h)\
-        : "d"((long)srcStride), "S"((long)dstStride), /*"m"(ff_pw_20), "m"(ff_pw_3),*/ "m"(temp), "m"(ROUNDER)\
+       : "d"((long)srcStride), "S"((long)dstStride),\ 
+         "m"(temp), "m"(ROUNDER),\
+         "m"(ff_pw_20), "m"(ff_pw_3)\
         : "memory"\
     );\
 }\
@@ -2140,10 +2142,10 @@
         "paddw %%mm5, %%mm5               \n\t" /* 2b */\
         "psubw %%mm5, %%mm6               \n\t" /* c - 2b */\
         "pshufw $0x06, %%mm0, %%mm5       \n\t" /* 0C0B0A0A */\
-        "pmullw "MANGLE(ff_pw_3)", %%mm6  \n\t" /* 3c - 6b */\
+        "pmullw %8, %%mm6  \n\t" /* 3c - 6b */\
         "paddw %%mm4, %%mm0               \n\t" /* a */\
         "paddw %%mm1, %%mm5               \n\t" /* d */\
-        "pmullw "MANGLE(ff_pw_20)", %%mm0 \n\t" /* 20a */\
+        "pmullw %7, %%mm0 \n\t" /* 20a */\
         "psubw %%mm5, %%mm0               \n\t" /* 20a - d */\
         "paddw %6, %%mm6                  \n\t"\
         "paddw %%mm6, %%mm0               \n\t" /* 20a - 6b + 3c - d */\
@@ -2161,8 +2163,8 @@
         "paddw %%mm5, %%mm4               \n\t" /* d */\
         "paddw %%mm2, %%mm2               \n\t" /* 2b */\
         "psubw %%mm2, %%mm3               \n\t" /* c - 2b */\
-        "pmullw "MANGLE(ff_pw_20)", %%mm1 \n\t" /* 20a */\
-        "pmullw "MANGLE(ff_pw_3)", %%mm3  \n\t" /* 3c - 6b */\
+        "pmullw %7, %%mm1 \n\t" /* 20a */\
+        "pmullw %8, %%mm3  \n\t" /* 3c - 6b */\
         "psubw %%mm4, %%mm3               \n\t" /* -6b + 3c - d */\
         "paddw %6, %%mm1                  \n\t"\
         "paddw %%mm1, %%mm3               \n\t" /* 20a - 6b + 3c - d */\
@@ -2175,7 +2177,9 @@
         "decl %2                          \n\t"\
         " jnz 1b                          \n\t"\
         : "+a"(src), "+c"(dst), "+g"(h)\
-        : "S"((long)srcStride), "D"((long)dstStride), /*"m"(ff_pw_20), "m"(ff_pw_3),*/ "m"(temp), "m"(ROUNDER)\
+        : "S"((long)srcStride), "D"((long)dstStride),\
+          "m"(temp), "m"(ROUNDER),\
+          "m"(ff_pw_20), "m"(ff_pw_3)\
         : "memory"\
     );\
 }\
@@ -2254,31 +2258,31 @@
         "movq 8(%0), %%mm1              \n\t"\
         "movq 16(%0), %%mm2             \n\t"\
         "movq 24(%0), %%mm3             \n\t"\
-        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %5, %6, %5, 16(%0),  8(%0),   (%0), 32(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %5, %6, %5,  8(%0),   (%0),   (%0), 40(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %7, %8, %5, 16(%0),  8(%0),   (%0), 32(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %7, %8, %5,  8(%0),   (%0),   (%0), 40(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %5, %6, %5,   (%0),   (%0),  8(%0), 48(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %7, %8, %5,   (%0),   (%0),  8(%0), 48(%0), (%1), OP)\
         \
-        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %5, %6, %5,   (%0),  8(%0), 16(%0), 56(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %7, %8, %5,   (%0),  8(%0), 16(%0), 56(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %5, %6, %5,  8(%0), 16(%0), 24(%0), 64(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %5, %6, %5, 16(%0), 24(%0), 32(%0), 72(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %7, %8, %5,  8(%0), 16(%0), 24(%0), 64(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %7, %8, %5, 16(%0), 24(%0), 32(%0), 72(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %5, %6, %5, 24(%0), 32(%0), 40(%0), 80(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %5, %6, %5, 32(%0), 40(%0), 48(%0), 88(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %7, %8, %5, 24(%0), 32(%0), 40(%0), 80(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %7, %8, %5, 32(%0), 40(%0), 48(%0), 88(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %5, %6, %5, 40(%0), 48(%0), 56(%0), 96(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %5, %6, %5, 48(%0), 56(%0), 64(%0),104(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %7, %8, %5, 40(%0), 48(%0), 56(%0), 96(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %7, %8, %5, 48(%0), 56(%0), 64(%0),104(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %5, %6, %5, 56(%0), 64(%0), 72(%0),112(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %5, %6, %5, 64(%0), 72(%0), 80(%0),120(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %7, %8, %5, 56(%0), 64(%0), 72(%0),112(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %7, %8, %5, 64(%0), 72(%0), 80(%0),120(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %5, %6, %5, 72(%0), 80(%0), 88(%0),128(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %7, %8, %5, 72(%0), 80(%0), 88(%0),128(%0), (%1), OP)\
         \
-        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %5, %6, %5, 80(%0), 88(%0), 96(%0),128(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %7, %8, %5, 80(%0), 88(%0), 96(%0),128(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"  \
-        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %5, %6, %5, 88(%0), 96(%0),104(%0),120(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %5, %6, %5, 96(%0),104(%0),112(%0),112(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %7, %8, %5, 88(%0), 96(%0),104(%0),120(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %7, %8, %5, 96(%0),104(%0),112(%0),112(%0), (%1, %3), OP)\
         \
         "add $136, %0                   \n\t"\
         "add %6, %1                     \n\t"\
@@ -2286,7 +2290,9 @@
         " jnz 1b                        \n\t"\
         \
         : "+r"(temp_ptr), "+r"(dst), "+g"(count)\
-        : "r"((long)dstStride), "r"(2*(long)dstStride), /*"m"(ff_pw_20), "m"(ff_pw_3),*/ "m"(ROUNDER), "g"(4-14*(long)dstStride)\
+        : "r"((long)dstStride), "r"(2*(long)dstStride),\
+        "m"(ROUNDER), "g"(4-14*(long)dstStride),\
+        "m"(ff_pw_20), "m"(ff_pw_3)\
         :"memory"\
     );\
 }\
@@ -2326,19 +2332,19 @@
         "movq 8(%0), %%mm1              \n\t"\
         "movq 16(%0), %%mm2             \n\t"\
         "movq 24(%0), %%mm3             \n\t"\
-        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %5, %6, %5, 16(%0),  8(%0),   (%0), 32(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %5, %6, %5,  8(%0),   (%0),   (%0), 40(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %7, %8, %5, 16(%0),  8(%0),   (%0), 32(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %7, %8, %5,  8(%0),   (%0),   (%0), 40(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %5, %6, %5,   (%0),   (%0),  8(%0), 48(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %7, %8, %5,   (%0),   (%0),  8(%0), 48(%0), (%1), OP)\
         \
-        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %5, %6, %5,   (%0),  8(%0), 16(%0), 56(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %7, %8, %5,   (%0),  8(%0), 16(%0), 56(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %5, %6, %5,  8(%0), 16(%0), 24(%0), 64(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm0, %%mm1, %%mm2, %%mm3, %7, %8, %5,  8(%0), 16(%0), 24(%0), 64(%0), (%1), OP)\
         \
-        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %5, %6, %5, 16(%0), 24(%0), 32(%0), 64(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm1, %%mm2, %%mm3, %%mm0, %7, %8, %5, 16(%0), 24(%0), 32(%0), 64(%0), (%1, %3), OP)\
         "add %4, %1                     \n\t"\
-        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %5, %6, %5, 24(%0), 32(%0), 40(%0), 56(%0), (%1), OP)\
-        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %5, %6, %5, 32(%0), 40(%0), 48(%0), 48(%0), (%1, %3), OP)\
+        QPEL_V_LOW(%%mm2, %%mm3, %%mm0, %%mm1, %7, %8, %5, 24(%0), 32(%0), 40(%0), 56(%0), (%1), OP)\
+        QPEL_V_LOW(%%mm3, %%mm0, %%mm1, %%mm2, %7, %8, %5, 32(%0), 40(%0), 48(%0), 48(%0), (%1, %3), OP)\
                 \
         "add $72, %0                    \n\t"\
         "add %6, %1                     \n\t"\
@@ -2346,7 +2352,9 @@
         " jnz 1b                        \n\t"\
          \
         : "+r"(temp_ptr), "+r"(dst), "+g"(count)\
-        : "r"((long)dstStride), "r"(2*(long)dstStride), /*"m"(ff_pw_20), "m"(ff_pw_3),*/ "m"(ROUNDER), "g"(4-6*(long)dstStride)\
+        : "r"((long)dstStride), "r"(2*(long)dstStride),\
+        "m"(ROUNDER), "g"(4-6*(long)dstStride),\
+        "m"(ff_pw_20), "m"(ff_pw_3)\
         : "memory"\
    );\
 }\
Index: libavcodec/i386/simple_idct_mmx.c
===================================================================
--- libavcodec/i386/simple_idct_mmx.c	(revision 11270)
+++ libavcodec/i386/simple_idct_mmx.c	(working copy)
@@ -363,7 +363,7 @@
         "movq " #src4 ", %%mm1          \n\t" /* R6     R2      r6      r2 */\
         "movq " #src1 ", %%mm2          \n\t" /* R3     R1      r3      r1 */\
         "movq " #src5 ", %%mm3          \n\t" /* R7     R5      r7      r5 */\
-        "movq "MANGLE(wm1010)", %%mm4   \n\t"\
+        "movq %3, %%mm4                 \n\t"\
         "pand %%mm0, %%mm4              \n\t"\
         "por %%mm1, %%mm4               \n\t"\
         "por %%mm2, %%mm4               \n\t"\
@@ -437,7 +437,7 @@
         "jmp 2f                         \n\t"\
         "1:                             \n\t"\
         "pslld $16, %%mm0               \n\t"\
-        "#paddd "MANGLE(d40000)", %%mm0 \n\t"\
+        "#paddd %4, %%mm0               \n\t"\
         "psrad $13, %%mm0               \n\t"\
         "packssdw %%mm0, %%mm0          \n\t"\
         "movq %%mm0, " #dst "           \n\t"\
@@ -471,7 +471,7 @@
         "movq " #src4 ", %%mm1          \n\t" /* R6     R2      r6      r2 */\
         "movq " #src1 ", %%mm2          \n\t" /* R3     R1      r3      r1 */\
         "movq " #src5 ", %%mm3          \n\t" /* R7     R5      r7      r5 */\
-        "movq "MANGLE(wm1010)", %%mm4   \n\t"\
+        "movq %3, %%mm4                 \n\t"\
         "pand %%mm0, %%mm4              \n\t"\
         "por %%mm1, %%mm4               \n\t"\
         "por %%mm2, %%mm4               \n\t"\
@@ -545,7 +545,7 @@
         "jmp 2f                         \n\t"\
         "1:                             \n\t"\
         "pslld $16, %%mm0               \n\t"\
-        "paddd "MANGLE(d40000)", %%mm0  \n\t"\
+        "paddd %4, %%mm0                \n\t"\
         "psrad $13, %%mm0               \n\t"\
         "packssdw %%mm0, %%mm0          \n\t"\
         "movq %%mm0, " #dst "           \n\t"\
@@ -1270,7 +1270,7 @@
 */
 
 "9: \n\t"
-                :: "r" (block), "r" (temp), "r" (coeffs)
+                :: "r" (block), "r" (temp), "r" (coeffs), "m" (wm1010), "m"(d40000)
                 : "%eax"
         );
 }
Index: libavcodec/i386/cavsdsp_mmx.c
===================================================================
--- libavcodec/i386/cavsdsp_mmx.c	(revision 11727)
+++ libavcodec/i386/cavsdsp_mmx.c	(working copy)
@@ -23,9 +23,31 @@
  */
 
 #include "dsputil.h"
-#include "dsputil_mmx.h"
 #include "common.h"
 
+#define SUMSUB_BA( a, b ) \
+"paddw "#b", "#a" \n\t"\
+"paddw "#b", "#b" \n\t"\
+"psubw "#a", "#b" \n\t"
+
+#define SBUTTERFLY(a,b,t,n,m)\
+"mov" #m " " #a ", " #t "         \n\t" /* abcd */\
+"punpckl" #n " " #b ", " #a "     \n\t" /* aebf */\
+"punpckh" #n " " #b ", " #t "     \n\t" /* cgdh */\
+
+#define TRANSPOSE4(a,b,c,d,t)\
+SBUTTERFLY(a,b,t,wd,q) /* a=aebf t=cgdh */\
+SBUTTERFLY(c,d,b,wd,q) /* c=imjn b=kolp */\
+SBUTTERFLY(a,c,d,dq,q) /* a=aeim d=bfjn */\
+SBUTTERFLY(t,b,c,dq,q) /* t=cgko c=dhlp */
+
+DECLARE_ALIGNED_8(static const uint64_t,ff_pw_4 ) = 0x0004000400040004ULL;	 
+DECLARE_ALIGNED_8(static const uint64_t,ff_pw_5 ) = 0x0005000500050005ULL;	 
+DECLARE_ALIGNED_8(static const uint64_t,ff_pw_7 ) = 0x0007000700070007ULL;	 
+DECLARE_ALIGNED_8(static const uint64_t,ff_pw_42) = 0x002A002A002A002AULL;	 
+DECLARE_ALIGNED_8(static const uint64_t,ff_pw_64) = 0x0040004000400040ULL;	 
+DECLARE_ALIGNED_8(static const uint64_t,ff_pw_96) = 0x0060006000600060ULL;
+
 /*****************************************************************************
  *
  * inverse transform
Index: libavcodec/i386/flacdsp_mmx.c
===================================================================
--- libavcodec/i386/flacdsp_mmx.c	(revision 11888)
+++ libavcodec/i386/flacdsp_mmx.c	(working copy)
@@ -26,7 +26,6 @@
     double c = 2.0 / (len-1.0);
     int n2 = len>>1;
     long i = -n2*sizeof(int32_t);
-    long j =  n2*sizeof(int32_t);
     asm volatile(
         "movsd   %0,     %%xmm7 \n\t"
         "movapd  %1,     %%xmm6 \n\t"
@@ -54,7 +53,7 @@
         "sub      $8,      %1       \n\t"\
         "add      $8,      %0       \n\t"\
         "jl 1b                      \n\t"\
-        :"+&r"(i), "+&r"(j)\
+        :"+&r"(i)\
         :"r"(w_data+n2), "r"(data+n2)\
     );
     if(len&1)
@@ -84,9 +83,11 @@
         long i = -len*sizeof(double);
         if(j == lag-2) {
             asm volatile(
-                "movsd     %6,     %%xmm0 \n\t"
-                "movsd     %6,     %%xmm1 \n\t"
-                "movsd     %6,     %%xmm2 \n\t"
+                "movsd     %0,     %%xmm0 \n\t"
+                "movsd     %0,     %%xmm1 \n\t"
+                "movsd     %0,     %%xmm2 \n\t"
+                :: "m"(*ff_pd_1) );
+            asm volatile(
                 "1:                       \n\t"
                 "movapd   (%4,%0), %%xmm3 \n\t"
                 "movupd -8(%5,%0), %%xmm4 \n\t"
@@ -109,12 +110,14 @@
                 "movsd     %%xmm1, %2     \n\t"
                 "movsd     %%xmm2, %3     \n\t"
                 :"+&r"(i), "=m"(autoc[j]), "=m"(autoc[j+1]), "=m"(autoc[j+2])
-                :"r"(data1+len), "r"(data1+len-j), "m"(*ff_pd_1)
+                :"r"(data1+len), "r"(data1+len-j)
             );
         } else {
             asm volatile(
-                "movsd     %5,     %%xmm0 \n\t"
-                "movsd     %5,     %%xmm1 \n\t"
+                "movsd     %0,     %%xmm0 \n\t"
+                "movsd     %0,     %%xmm1 \n\t"
+                :: "m"(*ff_pd_1) );
+            asm volatile(
                 "1:                       \n\t"
                 "movapd   (%3,%0), %%xmm3 \n\t"
                 "movupd -8(%4,%0), %%xmm4 \n\t"
@@ -131,7 +134,7 @@
                 "movsd     %%xmm0, %1     \n\t"
                 "movsd     %%xmm1, %2     \n\t"
                 :"+&r"(i), "=m"(autoc[j]), "=m"(autoc[j+1])
-                :"r"(data1+len), "r"(data1+len-j), "m"(*ff_pd_1)
+                :"r"(data1+len), "r"(data1+len-j)
             );
         }
     }
